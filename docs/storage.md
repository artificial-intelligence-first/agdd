---
title: AGDD Storage Layer
last_synced: 2025-10-24
description: Pluggable data management system for agent execution data and observability
change_log:
  - 2025-10-24: Added front-matter and architecture overview
---

# AGDD Storage Layer

The AGDD storage layer provides a pluggable, scalable data management system for querying and analyzing agent execution data.

## Overview

The storage layer provides CLI and API tools for managing observability data generated by agents. It supports:

- **Multiple backends**: SQLite (dev), PostgreSQL/TimescaleDB (prod), ClickHouse (analytics)
- **Full-text search**: Find events by content using FTS5 (SQLite) or full-text indexes (PostgreSQL)
- **Structured queries**: Query runs and events with filters
- **Lifecycle management**: Automatic cleanup and archival
- **Event envelope pattern**: Strongly-typed common fields + flexible JSON payloads

## Role Clarification

**Important**: The storage layer is designed for **data management and analysis**, not for agent development:

- **Agent developers**: Continue using `ObservabilityLogger` (injected via `obs` parameter in agent code)
- **Data analysts/operators**: Use the storage layer CLI commands to query and manage execution data
- **Migration tool**: Imports legacy `.runs/agents/` data into the storage layer for analysis

The storage layer complements (not replaces) the existing agent observability system.
Cost tracking is handled separately by `agdd.observability.cost_tracker` and persists artifacts under `.runs/costs/` (JSONL ledger and SQLite database).

## Architecture

### Event Envelope Pattern

All events follow a consistent structure:

```python
{
  "ts": "2025-10-23T10:30:00Z",           # Timestamp (indexed)
  "run_id": "mag-a1b2c3d4",               # Run identifier (indexed)
  "agent_slug": "offer-orchestrator-mag", # Agent slug (indexed)
  "type": "log",                          # Event type (indexed)
  "level": "info",                        # Log level
  "msg": "Started agent execution",       # Searchable message
  "payload": {...},                       # Flexible JSON data
  "span_id": "...",                       # OpenTelemetry span ID
  "contract_id": "...",                   # JSON Schema contract
  "artifact_uri": "s3://..."              # Artifact location
}
```

### Supported Event Types

- **`log`**: General log events (start, end, error, retry)
- **`mcp.call`**: Model Context Protocol calls
- **`metric`**: Metric observations (duration_ms, token_count, cost_usd)
- **`delegation`**: Agent delegations (MAG → SAG)
- **`artifact`**: Generated artifacts (code, reports, data)

## Configuration

### Environment Variables

```bash
# Storage backend selection
export AGDD_STORAGE_BACKEND=sqlite  # sqlite, postgres, timescale
export AGDD_STORAGE_DB_PATH=.agdd/storage.db  # SQLite only
export AGDD_STORAGE_ENABLE_FTS=true  # Enable full-text search

# PostgreSQL/TimescaleDB backend
export AGDD_STORAGE_DSN=postgresql://user:pass@localhost/agdd

# Data lifecycle
export AGDD_STORAGE_HOT_DAYS=7  # Keep hot data for 7 days
export AGDD_STORAGE_ARCHIVE_ENABLED=false
export AGDD_STORAGE_ARCHIVE_DESTINATION=s3://bucket/prefix
```

### Settings File

Alternatively, create `.env`:

```ini
AGDD_STORAGE_BACKEND=sqlite
AGDD_STORAGE_DB_PATH=.agdd/storage.db
AGDD_STORAGE_ENABLE_FTS=true
AGDD_STORAGE_HOT_DAYS=7
```

## Usage

### Initialize Storage

```bash
# Initialize SQLite storage (default)
agdd data init

# Initialize with custom path
agdd data init --backend sqlite --db-path /var/agdd/storage.db

# Disable full-text search
agdd data init --no-fts
```

### Query Runs

```bash
# List recent runs
agdd data query --limit 10

# List runs for specific agent
agdd data query --agent offer-orchestrator-mag --limit 20

# List failed runs
agdd data query --status failed

# Get specific run details
agdd data query --run-id mag-a1b2c3d4
```

### Search Events

```bash
# Full-text search across all events
agdd data search "error rate limit"

# Search within specific agent
agdd data search "token" --agent offer-orchestrator-mag

# Limit results
agdd data search "exception" --limit 50
```

### Data Management

```bash
# Preview cleanup (dry run)
agdd data vacuum --hot-days 7 --dry-run

# Delete data older than 7 days
agdd data vacuum --hot-days 7

# Archive old data to S3 (future)
agdd data archive s3://my-bucket/agdd-archive --since 30
```

## Migration from Legacy Storage

If you have existing data in `.runs/agents/`, migrate it:

```bash
# Preview migration
python ops/scripts/migrate_to_storage.py --source .runs/agents --dry-run

# Perform migration
python ops/scripts/migrate_to_storage.py --source .runs/agents

# Custom database path
python ops/scripts/migrate_to_storage.py \
  --source .runs/agents \
  --backend sqlite \
  --db-path /var/agdd/storage.db
```

Cost ledgers produced after the migration live in `.runs/costs/` and do not require conversion; back up both `costs.jsonl` and `costs.db` for historical analysis.

## Programmatic Access

### Python API (for custom tools)

```python
from agdd.storage import get_storage_backend

async def example():
    # Get storage backend
    storage = await get_storage_backend()

    # List recent runs
    runs = await storage.list_runs(limit=10)

    # Get specific run
    run = await storage.get_run("mag-a1b2c3d4")

    # Stream events (asynchronous iterator)
    async for event in storage.get_events("mag-a1b2c3d4"):
        print(event)

    # Full-text search
    results = await storage.search_text("error", limit=100)

    # Cleanup
    await storage.close()
```

### Custom Storage Backend (Advanced)

To implement a custom backend, inherit from `StorageBackend`:

```python
from agdd.storage.base import StorageBackend, StorageCapabilities

class MyCustomBackend(StorageBackend):
    @property
    def capabilities(self) -> StorageCapabilities:
        return StorageCapabilities(
            append_event=True,
            search_text=True,
            # ...
        )

    async def initialize(self) -> None:
        # Initialize your backend
        pass

    async def append_event(self, ...):
        # Implement event storage
        pass

    # Implement other abstract methods...
```

## Storage Backends

### SQLite (Default)

**Best for:**
- Local development
- Small deployments
- Single-instance applications

**Features:**
- Zero configuration
- FTS5 full-text search
- WAL mode for concurrent access
- Single file database

**Limitations:**
- Limited concurrent writes
- No distributed deployments
- Manual lifecycle management

**Recommendations:**
- Use Litestream for automatic S3 replication
- Suitable for up to ~10,000 runs/day

### PostgreSQL/TimescaleDB

**Best for:**
- Production deployments
- Multi-instance applications
- Large-scale data

**Features:**
- JSONB with GIN indexes
- Full-text search via `to_tsvector`
- Connection pooling with `asyncpg`
- Compatible with TimescaleDB compression/retention policies

**Recommendations:**
- Install the `asyncpg` extra (`pip install agdd[postgres]`)
- Enable TimescaleDB extension for large-scale retention
- Apply retention/compression policies for long-term storage

### ClickHouse (Future)

**Best for:**
- Analytics and exploration
- Very large datasets
- Complex aggregations

**Features:**
- Columnar storage
- Extremely fast aggregations
- TTL/partitioning
- S3/Parquet integration

**Recommendations:**
- Use as read-replica for analytics
- Ingest from PostgreSQL or Parquet files
- Suitable for billions of events

## Data Lifecycle

### Hot/Warm/Cold Strategy

```
┌─────────────┐
│  Hot (0-7d) │ → SQLite/PostgreSQL (fast queries)
└─────────────┘
       ↓
┌─────────────┐
│ Warm (7-30d)│ → PostgreSQL (compressed)
└─────────────┘
       ↓
┌─────────────┐
│ Cold (30d+) │ → S3/MinIO (Parquet) + ClickHouse
└─────────────┘
```

### Retention Policies

Configure automatic cleanup:

```bash
# Keep hot data for 7 days, delete older
export AGDD_STORAGE_HOT_DAYS=7

# Enable archival to S3 before deletion
export AGDD_STORAGE_ARCHIVE_ENABLED=true
export AGDD_STORAGE_ARCHIVE_DESTINATION=s3://my-bucket/archive
```

### TimescaleDB Policies (Optional)

```sql
-- Auto-compress chunks older than 3 days
SELECT add_compression_policy('events', INTERVAL '3 days');

-- Auto-drop chunks older than 30 days
SELECT add_retention_policy('events', INTERVAL '30 days');
```

## Best Practices

### Development

1. Use SQLite with default settings
2. Enable FTS5 for local search
3. Run `agdd data vacuum` periodically
4. Keep database in `.agdd/` directory

### Production

1. Use PostgreSQL + TimescaleDB
2. Configure retention policies
3. Enable archival to S3/MinIO
4. Set up automated backups
5. Monitor disk usage
6. Use connection pooling

### Analytics

1. Export to Parquet regularly
2. Load into ClickHouse or DuckDB
3. Query S3 directly with DuckDB
4. Use pre-aggregated views

## Troubleshooting

### "FTS5 not available"

SQLite was compiled without FTS5 support. Options:
1. Disable FTS: `agdd data init --no-fts`
2. Install SQLite with FTS5: `conda install sqlite` or rebuild from source

### "Database is locked"

SQLite is in use by another process. Solutions:
1. Close other connections
2. Check WAL mode: `PRAGMA journal_mode=WAL`
3. Increase timeout in application

### "Too many events"

Database is growing too large. Solutions:
1. Run vacuum: `agdd data vacuum --hot-days 7`
2. Enable archival to S3
3. Migrate to PostgreSQL/TimescaleDB

## Future Enhancements

### Phase 2 (Planned)

- PostgreSQL/TimescaleDB backend
- S3/MinIO archival
- Parquet export
- Automatic lifecycle management
- Litestream integration guide

### Phase 3 (Planned)

- ClickHouse backend
- pgvector similarity search
- OpenTelemetry export
- Grafana/Prometheus integration
- Real-time streaming APIs

## References

- [SQLite FTS5](https://www.sqlite.org/fts5.html)
- [PostgreSQL JSONB](https://www.postgresql.org/docs/current/datatype-json.html)
- [TimescaleDB](https://docs.timescale.com/)
- [Litestream](https://litestream.io/)
- [ClickHouse](https://clickhouse.com/docs/)
- [OpenTelemetry Semantic Conventions](https://opentelemetry.io/docs/concepts/semantic-conventions/)
