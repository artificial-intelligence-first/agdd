# AGDD HTTP API Configuration
# Copy this file to .env and customize values for your environment

# ============================================================================
# Core API Settings
# ============================================================================

# Server host and port (for uvicorn)
AGDD_API_HOST=0.0.0.0
AGDD_API_PORT=8000

# API prefix for all endpoints
AGDD_API_PREFIX=/api/v1

# Enable debug mode (detailed logs, hot reload)
AGDD_API_DEBUG=false

# Base directory for run artifacts
AGDD_RUNS_BASE_DIR=.runs/agents

# ============================================================================
# Authentication & Security
# ============================================================================

# API key for authentication
# Generate with: openssl rand -hex 32
# Leave commented out to disable authentication (development only)
# AGDD_API_KEY=your-secret-key-here

# CORS allowed origins
# For development: ["*"]
# For production: ["https://yourdomain.com","https://app.yourdomain.com"]
AGDD_CORS_ORIGINS=["*"]

# Allow credentials in CORS requests
AGDD_CORS_ALLOW_CREDENTIALS=false

# ============================================================================
# Rate Limiting
# ============================================================================

# Maximum requests per second per client IP
# Comment out or leave empty to disable rate limiting
# AGDD_RATE_LIMIT_QPS=10

# Redis URL for distributed rate limiting (multi-process deployments)
# Format: redis://localhost:6379/0
# Comment out or leave empty to use in-memory rate limiter
# AGDD_REDIS_URL=redis://localhost:6379/0

# ============================================================================
# Anthropic API Integration
# ============================================================================

# Anthropic API key for batch processing and optimization
# Get your API key from: https://console.anthropic.com/settings/keys
# Required for: Batch Manager, AI-powered agents
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# ============================================================================
# GitHub Integration
# ============================================================================

# Webhook signature verification secret
# Set the same value in GitHub webhook configuration
# AGDD_GITHUB_WEBHOOK_SECRET=your-webhook-secret

# GitHub personal access token for posting comments
# Required scopes: repo (for private repos) or public_repo (for public repos)
# AGDD_GITHUB_TOKEN=ghp_your_token_here

# ============================================================================
# LLM Provider Configuration
# ============================================================================

# OpenAI API key for provider integration
# Required for OpenAI provider and batch processing
# Get your key at: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI Moderation settings (uses omni-moderation-latest by default)
# Uncomment to override moderation API key/model when plan.moderation=true
# OPENAI_MODERATION_API_KEY=sk-your-openai-api-key-here
# OPENAI_MODERATION_MODEL=omni-moderation-latest

# Anthropic API key for Claude models
# Get your key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# Google Generative AI Provider
# API key for Google's generative AI services
# Get your API key from: https://makersuite.google.com/app/apikey
# GOOGLE_API_KEY=your-google-api-key-here

# SDK type to use: "google-generativeai" (legacy) or "google-genai" (new)
# Default: google-generativeai
# GOOGLE_SDK_TYPE=google-generativeai

# Model name to use (e.g., gemini-1.5-pro, gemini-2.0-flash)
# Default: gemini-1.5-pro
# GOOGLE_MODEL_NAME=gemini-1.5-pro

# Local LLM Provider Settings (vLLM, Ollama)
# Base URL for OpenAI-compatible local LLM server (must end with /)
# Common endpoints:
#   - vLLM: http://localhost:8000/v1/
#   - Ollama: http://localhost:11434/v1/
# AGDD_LOCAL_LLM_BASE_URL=http://localhost:8000/v1/

# API key for local LLM server (optional, some servers require it)
# AGDD_LOCAL_LLM_API_KEY=

# Request timeout in seconds for local LLM calls
# AGDD_LOCAL_LLM_TIMEOUT=60.0

# ============================================================================
# Observability & Monitoring
# ============================================================================

# OpenTelemetry Tracing
# Enable distributed tracing with OpenTelemetry
AGDD_OTEL_TRACING_ENABLED=false

# OpenTelemetry Metrics
# Enable metrics collection with OpenTelemetry
AGDD_OTEL_METRICS_ENABLED=false

# Service name for traces and metrics
AGDD_SERVICE_NAME=agdd

# OTLP endpoint for traces and metrics
# For local Jaeger: http://localhost:4318
# For production: your OTLP collector endpoint
# AGDD_OTLP_ENDPOINT=http://localhost:4318

# Langfuse Integration
# Enable Langfuse for LLM observability
AGDD_LANGFUSE_ENABLED=false

# Langfuse API credentials
# Get these from https://cloud.langfuse.com or your self-hosted instance
# LANGFUSE_PUBLIC_KEY=pk_your_public_key
# LANGFUSE_SECRET_KEY=sk_your_secret_key

# Langfuse host (default: https://cloud.langfuse.com)
# For self-hosted: https://your-langfuse-instance.com
# LANGFUSE_HOST=https://cloud.langfuse.com

# Cost Tracking
# Paths for cost tracking storage
# AGDD_COST_JSONL_PATH=.agdd/costs.jsonl
# AGDD_COST_DB_PATH=.agdd/costs.db
# AGDD_COST_SQLITE_ENABLED=true

# ============================================================================
# Semantic Cache Configuration
# ============================================================================

# Cache backend type (faiss or redis)
# FAISS: Local in-memory cache with approximate nearest neighbor search
# Redis: Distributed cache with Redis Vector Index (requires Redis Stack)
AGDD_CACHE_BACKEND=faiss

# Embedding dimension (must match your embedding model)
# Common values: 768 (BERT), 1536 (OpenAI), 384 (MiniLM)
AGDD_CACHE_DIMENSION=768

# Redis Vector Index configuration (only used when backend=redis)
# AGDD_CACHE_REDIS_URL=redis://localhost:6379
# AGDD_CACHE_REDIS_INDEX_NAME=agdd_cache

# FAISS index configuration (only used when backend=faiss)
# Index types: Flat (exact search), IVFFlat (approximate nearest neighbor)
# Note: Flat is recommended for <10k entries, IVFFlat for larger datasets
AGDD_CACHE_FAISS_INDEX_TYPE=Flat
AGDD_CACHE_FAISS_NLIST=100

# ============================================================================
# Production Deployment Example
# ============================================================================
# Uncomment and customize these values for production deployment:
#
# AGDD_API_HOST=0.0.0.0
# AGDD_API_PORT=8000
# AGDD_API_DEBUG=false
# AGDD_API_KEY=your-generated-secret-key-here
# AGDD_CORS_ORIGINS=["https://yourdomain.com","https://app.yourdomain.com"]
# AGDD_CORS_ALLOW_CREDENTIALS=false
# AGDD_RATE_LIMIT_QPS=10
# AGDD_REDIS_URL=redis://redis:6379/0
# AGDD_GITHUB_WEBHOOK_SECRET=your-webhook-secret
# AGDD_GITHUB_TOKEN=ghp_your_token_here
